{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "from scipy.io import savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = ['hongzhi', 'Istanbul', 'Jakarta', 'KualaLampur', 'NYC', 'SaoPaulo', 'TKY']\n",
    "data_inprefix = 'dataset/cleaned_'\n",
    "data_insufix = '.mat'\n",
    "\n",
    "data_outprefix = 'input/'\n",
    "data_outsufix = '_friendPOI.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/cleaned_hongzhi.mat\n",
      "before: 255557\n",
      "after: 105327\n",
      "(7316, 2) (105327, 2)\n",
      "Num location: 13105, num friend: 112643\n",
      "dataset/cleaned_Istanbul.mat\n",
      "before: 908162\n",
      "after: 399689\n",
      "(21354, 2) (399689, 2)\n",
      "Num location: 12693, num friend: 421043\n",
      "dataset/cleaned_Jakarta.mat\n",
      "before: 378559\n",
      "after: 152917\n",
      "(11207, 2) (152917, 2)\n",
      "Num location: 8826, num friend: 164124\n",
      "dataset/cleaned_KualaLampur.mat\n",
      "before: 526405\n",
      "after: 233500\n",
      "(16161, 2) (233500, 2)\n",
      "Num location: 10817, num friend: 249661\n",
      "dataset/cleaned_NYC.mat\n",
      "before: 105961\n",
      "after: 48840\n",
      "(8723, 2) (48840, 2)\n",
      "Num location: 3628, num friend: 57563\n",
      "dataset/cleaned_SaoPaulo.mat\n",
      "before: 249839\n",
      "after: 74443\n",
      "(9655, 2) (74443, 2)\n",
      "Num location: 6286, num friend: 84098\n",
      "dataset/cleaned_TKY.mat\n",
      "before: 699324\n",
      "after: 245275\n",
      "(37480, 2) (245275, 2)\n",
      "Num location: 10856, num friend: 282755\n"
     ]
    }
   ],
   "source": [
    "locations = set()\n",
    "for ele in data_names:\n",
    "    in_path = '{}{}{}'.format(data_inprefix, ele, data_insufix)\n",
    "    print(in_path)\n",
    "    in_data = loadmat(in_path)\n",
    "    old_friends = in_data['friendship_old']\n",
    "    selected_checkins = in_data['selected_checkins']\n",
    "    new_friends0 = selected_checkins[:,0].reshape(-1, 1)\n",
    "    new_friends1 = selected_checkins[:,2].reshape(-1, 1)\n",
    "    location = np.unique(new_friends1)\n",
    "    \n",
    "    new_location = [max(np.max(old_friends), np.max(new_friends0)) + i + 1 for i in range(len(location))]\n",
    "    new_location = np.array(new_location)\n",
    "    location_dict = {location[i]: new_location[i] for i in range(len(location))}\n",
    "    new_friends1 = np.array([location_dict[new_friends1[i][0]] for i in range(len(new_friends1))]).reshape(-1, 1)\n",
    "    \n",
    "    new_friends = np.concatenate((new_friends0, new_friends1), axis=1)\n",
    "    print(\"before: {}\".format(len(new_friends)))\n",
    "    new_friends = np.unique(new_friends, axis=0)\n",
    "    print(\"after: {}\".format(len(new_friends)))\n",
    "    \n",
    "    with open('{}location_{}'.format(data_outprefix, ele), 'w', encoding='utf-8') as file:\n",
    "        for elee in new_location:\n",
    "            file.write('{}\\n'.format(elee))\n",
    "    print(old_friends.shape, new_friends.shape)\n",
    "    final_friends = np.concatenate((old_friends, new_friends))\n",
    "    print(\"Num location: {}, num friend: {}\".format(len(new_location), len(final_friends)))\n",
    "    \n",
    "    with open('{}{}{}'.format(data_outprefix, ele, data_outsufix), 'w', encoding='utf-8') as file:\n",
    "        file.write('id1,id2\\n')\n",
    "        for i in range(len(final_friends)):\n",
    "            this = final_friends[i]\n",
    "            source = this[0]\n",
    "            target = this[1]\n",
    "            file.write('{},{}\\n'.format(source, target))\n",
    "            \n",
    "    with open('Suhi_output/location_dict_{}'.format(ele), 'w', encoding='utf-8') as file:\n",
    "        for key, value in location_dict.items():\n",
    "            file.write('{}\\t{}\\n'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYC_data_path = 'dataset/dataset_connected_NYC.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(NYC_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_checkins = data['selected_checkins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1801,      39,   17807,      70],\n",
       "       [    105,      39,    5708,      33],\n",
       "       [    571,      39,    3968,     300],\n",
       "       ...,\n",
       "       [    718,      59,   12596,      70],\n",
       "       [   1446,      59,  104201,     279],\n",
       "       [   2305,      60, 1692889,     190]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_friendship = data['friendship_old']\n",
    "new_friendship = data['friendship_new']\n",
    "friendship = np.concatenate((old_friendship, new_friendship), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    2],\n",
       "       [   1,   24],\n",
       "       [   1,   30],\n",
       "       ...,\n",
       "       [3959, 3965],\n",
       "       [3970, 4000],\n",
       "       [3981, 3991]], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friendship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colocation_friendship_statistics(friends, checkins):\n",
    "    def get_checkin_from_user(user, checkins):\n",
    "        locations = set()\n",
    "        for i in range(len(checkins)):\n",
    "            if checkins[i][0] == user:\n",
    "                locations.add(checkins[i][2])\n",
    "        return locations\n",
    "    \n",
    "    def jaccard_similarity(set1, set2):\n",
    "        inter = set1.intersection(set2)\n",
    "        uni = set1.union(set2)\n",
    "        if len(uni) == 0:\n",
    "            return 0\n",
    "        return len(inter) / len(uni)\n",
    "    \n",
    "    simis = []\n",
    "    \n",
    "    for i in tqdm(range(len(friends))):\n",
    "        source, target = friends[i][0], friends[i][1]\n",
    "        source_checkins = get_checkin_from_user(source, checkins)\n",
    "        target_checkins = get_checkin_from_user(target, checkins)        \n",
    "        simis.append(jaccard_similarity(source_checkins, target_checkins))\n",
    "    return np.mean(simis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19268/19268 [56:47<00:00,  5.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02626099581260058"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colocation_friendship_statistics(friendship, selected_checkins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = 'Suhi_output/ego_net_NYC.txt'\n",
    "edge_list = 'Suhi_output/edgelist_NYC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = dict()\n",
    "with open(map_dict, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data_line = line.strip().split(',')\n",
    "        maps[data_line[0]] = data_line[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_checkins_dict = dict()\n",
    "for i in range(len(selected_checkins)):\n",
    "    user = selected_checkins[i][0]\n",
    "    venue = selected_checkins[i][2]\n",
    "    if user not in user_checkins_dict:\n",
    "        user_checkins_dict[user] = set([venue])\n",
    "    else:\n",
    "        user_checkins_dict[user].add(venue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3785"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_checkins_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4024"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(user_checkins_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "ego_net =nx.read_edgelist(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkin_from_user(user, checkins):\n",
    "    try:\n",
    "        return user_checkins_dict[int(user)]\n",
    "    except:\n",
    "#         print(user)\n",
    "        return set()\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    inter = set1.intersection(set2)\n",
    "    uni = set1.union(set2)\n",
    "    if len(uni) == 0:\n",
    "        return 0\n",
    "    return len(inter) / len(uni)\n",
    "\n",
    "\n",
    "def colocation_friendship_statistics_for_ego(ego_net, checkins, maps):\n",
    "    scores = []\n",
    "    count = 0\n",
    "    for node in tqdm(ego_net.nodes()):\n",
    "        neighbors = ego_net.neighbors(node)\n",
    "#         print(neighbors)\n",
    "        if len(neighbors) > 1:\n",
    "            for i in range(len(neighbors) - 1):\n",
    "                for j in range(i + 1, len(neighbors)):\n",
    "                    if ego_net.has_edge(neighbors[i], neighbors[j]):\n",
    "                        node_i = int(maps[neighbors[i]])\n",
    "                        node_j = int(maps[neighbors[j]])\n",
    "                        location_i = get_checkin_from_user(node_i, checkins)\n",
    "                        location_j = get_checkin_from_user(node_j, checkins)\n",
    "                        score = jaccard_similarity(location_i, location_j)\n",
    "                        scores.append(score)\n",
    "        count += 1\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                              | 0/11412 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11412/11412 [00:00<00:00, 70632.73it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.026604663944231395"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colocation_friendship_statistics_for_ego(ego_net, selected_checkins, maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendship_old = np.load('CA Dataset/old_friendship_new.npy')\n",
    "friendship_new = np.load('CA Dataset/new_friendship_new.npy')\n",
    "selected_checkins = np.load('CA Dataset/selected_checkins_new.npy')\n",
    "\n",
    "dictt = {'friendship_old': friendship_old, 'friendship_new': friendship_new, 'selected_checkins': selected_checkins}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('dataset/dataset_connected_hongzhi.mat', dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
